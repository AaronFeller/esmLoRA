{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import esm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import loralib as lora\n",
    "import esmLoRA.esm as el\n",
    "from esmLoRA.esm.model.esm2 import ESM2\n",
    "import pytorch_lightning as pl\n",
    "import math\n",
    "from Bio import SeqIO\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from tensordict import TensorDict\n",
    "\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ESM model\n",
    "\n",
    "#model used on this exemple available on git, most recent version \n",
    "pretrained_model, alphabet = el.pretrained.esm2_t6_8M_UR50D()\n",
    "\n",
    "# Load batch converter\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "# Disable dropout for deterministic results\n",
    "pretrained_model.eval()\n",
    "\n",
    "# Save weights from pretrained model\n",
    "# PATH = 'esm2_t6_8M_UR50D_pretrained_checkpoint.pt'\n",
    "# torch.save(pretrained_model.state_dict(), PATH)\n",
    "\n",
    "# Load previously saved weights, should all match\n",
    "#pretrained_model.load_state_dict(torch.load(PATH), strict=False)\n",
    "\n",
    "# Load model using ESM2 framework (edited version of ESM2)\n",
    "model = ESM2(num_layers=6, embed_dim=320, attention_heads=20, token_dropout=False)\n",
    "\n",
    "# Load weights from pretrained model\n",
    "# Set path (same as saved above)\n",
    "PATH = 'esm2_t6_8M_UR50D_pretrained_checkpoint.pt'\n",
    "\n",
    "# Load weights to ESM2 model (Should error with missing weights from LoRA)\n",
    "model.load_state_dict(torch.load(PATH), strict=False)\n",
    "\n",
    "#Generate mapping for tokens to amino acids\n",
    "\n",
    "# Pull mapping from alphabet\n",
    "token_mapping = alphabet.to_dict() # {amino_acid: token_id}\n",
    "\n",
    "# Reverse the mapping\n",
    "token_mapping = {v: k for k, v in token_mapping.items()} # {token_id: amino_acid}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test alphabet encode, print tokens \n",
    "# input_tokens = torch.Tensor([alphabet.encode(\"<cls>MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG<eos><pad><pad><pad><pad>\")]).to(torch.int64)\n",
    "# input_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.5450e+01, -8.9811e+00, -6.8793e+00, -8.9750e+00, -1.4604e-01,\n",
      "         5.2747e-01,  4.9740e-02,  3.4032e-01,  1.5516e-01, -1.9002e-01,\n",
      "         3.1542e-01,  3.6667e-01, -3.8365e-01, -8.8549e-01, -2.9278e+00,\n",
      "        -4.5261e-01, -6.4824e-03, -1.6359e+00, -1.3195e+00, -2.1832e-01,\n",
      "         1.9455e+00, -1.8578e+00, -2.6934e+00, -3.6608e-01, -4.1013e-01,\n",
      "        -1.1099e+01, -1.1333e+01, -1.1781e+01, -1.4696e+01, -1.5194e+01,\n",
      "        -1.5063e+01, -1.5312e+01, -8.9679e+00], grad_fn=<SelectBackward0>)\n",
      "33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<cls>MSTVRQERLKSIVRILERLSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGGYVLAEG<eos>ARRG'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test encoding with masked values\n",
    "\n",
    "#Set input tokens that include masked values\n",
    "input_tokens = torch.Tensor([alphabet.encode(\"<cls>M<mask>TVRQERLKSIVRILER<mask>SKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRG<mask>YVLA<mask>G<eos><pad><pad><pad><pad>\")], )\n",
    "#input_tokens.to(torch.int64)\n",
    "\n",
    "# Pull logits from model based on input tokens above\n",
    "var = model.forward(input_tokens.int(), return_contacts = False)['logits']\n",
    "print(var[0][0])\n",
    "print(len(var[0][0]))\n",
    "\n",
    "# Make prediction using argmax\n",
    "prediction = var[0,:].argmax(dim=1)\n",
    "\n",
    "# Reconstruct the sequence using the token mapping\n",
    "reconstructed = ''\n",
    "for token in prediction:\n",
    "    reconstructed += token_mapping[token.item()]\n",
    "reconstructed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.0085, -0.0014, -0.0319,  ...,  0.0292, -0.0222,  0.0454],\n",
      "        [ 0.0132, -0.0434, -0.0193,  ..., -0.0275, -0.0431,  0.0065],\n",
      "        [-0.0115,  0.0435, -0.0405,  ..., -0.0415, -0.0135, -0.0348],\n",
      "        ...,\n",
      "        [ 0.0573, -0.0326,  0.0628,  ...,  0.0367,  0.0041,  0.0364],\n",
      "        [ 0.0218, -0.0299,  0.0414,  ..., -0.0203,  0.0226,  0.0147],\n",
      "        [-0.0314,  0.0071,  0.0014,  ..., -0.0147, -0.0373,  0.0111]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0117, -0.0116, -0.0118,  ...,  0.0107,  0.0113, -0.0112],\n",
      "        [-0.0119, -0.0118, -0.0112,  ..., -0.0114, -0.0110, -0.0069],\n",
      "        [ 0.0110, -0.0107,  0.0092,  ...,  0.0119,  0.0120, -0.0113],\n",
      "        ...,\n",
      "        [ 0.0119,  0.0119,  0.0119,  ...,  0.0116,  0.0051, -0.0119],\n",
      "        [ 0.0118,  0.0118,  0.0119,  ...,  0.0119,  0.0119,  0.0110],\n",
      "        [-0.0116, -0.0056, -0.0115,  ..., -0.0118, -0.0118, -0.0022]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0171,  0.0158,  0.0333,  ...,  0.0196, -0.0023,  0.0109],\n",
      "        [ 0.0193,  0.0291, -0.0063,  ...,  0.0128, -0.0048,  0.0088],\n",
      "        [-0.0180, -0.0074, -0.0229,  ..., -0.0338,  0.0126,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0143,  0.0064,  0.0215,  ...,  0.0041,  0.0180,  0.0342],\n",
      "        [-0.0289, -0.0217, -0.0278,  ...,  0.0104,  0.0050,  0.0101],\n",
      "        [ 0.0182,  0.0314,  0.0234,  ...,  0.0095,  0.0196, -0.0026]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0106,  0.0112, -0.0116,  ..., -0.0044, -0.0114,  0.0111],\n",
      "        [-0.0111, -0.0111,  0.0113,  ..., -0.0105,  0.0116, -0.0111],\n",
      "        [-0.0112, -0.0112,  0.0117,  ..., -0.0053,  0.0115, -0.0111],\n",
      "        ...,\n",
      "        [-0.0109, -0.0119,  0.0119,  ...,  0.0116,  0.0118, -0.0110],\n",
      "        [ 0.0062,  0.0114, -0.0110,  ..., -0.0025, -0.0117,  0.0043],\n",
      "        [ 0.0115,  0.0113, -0.0114,  ...,  0.0053, -0.0115,  0.0114]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0113,  0.0408,  0.0330,  ...,  0.0387, -0.0089,  0.0563],\n",
      "        [ 0.0107,  0.0656,  0.0601,  ...,  0.0223,  0.0286, -0.0271],\n",
      "        [-0.0387, -0.0426,  0.0220,  ..., -0.0386,  0.0374, -0.0104],\n",
      "        ...,\n",
      "        [ 0.0341, -0.0197,  0.0094,  ..., -0.0269, -0.0436, -0.0450],\n",
      "        [ 0.0630,  0.0494, -0.0226,  ...,  0.0398,  0.0188, -0.0385],\n",
      "        [-0.0064, -0.0371, -0.0210,  ..., -0.0136, -0.0552, -0.0468]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 5.3688e-05, -1.0762e-02, -4.5260e-03,  ...,  1.2055e-02,\n",
      "          1.1969e-02, -1.1816e-02],\n",
      "        [ 1.0021e-02, -1.1817e-02, -1.1842e-02,  ..., -1.1789e-02,\n",
      "         -1.1747e-02,  1.1760e-02],\n",
      "        [-8.8777e-04,  1.1067e-02, -1.1030e-02,  ..., -1.1267e-02,\n",
      "          1.1207e-02, -1.1074e-02],\n",
      "        ...,\n",
      "        [-1.1535e-02, -1.6140e-03, -1.1748e-02,  ...,  1.1940e-03,\n",
      "         -1.1682e-02, -1.4460e-03],\n",
      "        [-4.9994e-03,  1.1950e-02, -1.3487e-03,  ..., -1.1005e-02,\n",
      "          1.2119e-02,  1.0838e-02],\n",
      "        [ 1.1331e-02,  1.1903e-02,  1.1847e-02,  ...,  1.1375e-02,\n",
      "          1.1865e-02, -1.1872e-02]], requires_grad=True), Parameter containing:\n",
      "tensor([[-1.6686e-02,  1.4346e-02,  2.1285e-02,  ..., -2.8776e-03,\n",
      "          2.4701e-03,  1.4924e-02],\n",
      "        [ 2.8268e-02,  1.2271e-02,  2.8272e-02,  ...,  1.9542e-02,\n",
      "          2.9618e-02, -4.5854e-03],\n",
      "        [ 4.0077e-04, -2.7396e-02, -2.4461e-03,  ..., -3.1448e-02,\n",
      "          4.8313e-05, -1.8413e-02],\n",
      "        ...,\n",
      "        [ 1.2380e-02,  3.1056e-02,  2.4475e-02,  ...,  6.5163e-03,\n",
      "          3.4539e-02,  3.2535e-03],\n",
      "        [-9.2777e-03,  1.7071e-02,  3.7196e-03,  ...,  1.2297e-02,\n",
      "         -2.3881e-02,  5.3181e-03],\n",
      "        [-1.2293e-02,  5.3860e-04, -1.5198e-02,  ...,  1.5320e-02,\n",
      "          7.5857e-03, -1.6610e-02]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0116, -0.0108,  0.0051,  ..., -0.0053,  0.0115, -0.0108],\n",
      "        [-0.0117, -0.0109,  0.0060,  ..., -0.0105,  0.0115, -0.0111],\n",
      "        [-0.0113, -0.0113,  0.0113,  ..., -0.0113,  0.0118, -0.0063],\n",
      "        ...,\n",
      "        [ 0.0116,  0.0052, -0.0106,  ...,  0.0110, -0.0114,  0.0111],\n",
      "        [-0.0116, -0.0112,  0.0107,  ..., -0.0112,  0.0116, -0.0110],\n",
      "        [ 0.0115,  0.0111, -0.0108,  ...,  0.0111, -0.0117,  0.0106]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0227,  0.0165,  0.0404,  ...,  0.0216, -0.0332, -0.0023],\n",
      "        [-0.0492, -0.0225, -0.0116,  ..., -0.0647, -0.0244,  0.0437],\n",
      "        [ 0.0391, -0.0203,  0.0547,  ...,  0.0306, -0.0260, -0.0351],\n",
      "        ...,\n",
      "        [-0.0514,  0.0135, -0.0069,  ..., -0.0116, -0.0286, -0.0271],\n",
      "        [-0.0156,  0.0039,  0.0316,  ..., -0.0094,  0.0074, -0.0048],\n",
      "        [ 0.0229,  0.0566, -0.0369,  ..., -0.0241, -0.0358,  0.0558]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 1.1896e-02,  2.6183e-04, -1.1737e-02,  ...,  1.1858e-02,\n",
      "         -1.1907e-02, -1.1908e-02],\n",
      "        [ 1.1757e-02,  1.1827e-02, -3.1446e-03,  ...,  1.1758e-02,\n",
      "         -1.1852e-02, -1.1787e-02],\n",
      "        [ 1.1928e-02,  1.1897e-02,  3.9693e-05,  ...,  1.1889e-02,\n",
      "         -1.1851e-02, -1.1930e-02],\n",
      "        ...,\n",
      "        [-5.0828e-03, -1.1484e-02, -1.1976e-02,  ...,  1.1999e-02,\n",
      "         -1.1960e-02, -1.2018e-02],\n",
      "        [ 1.1906e-02,  1.1848e-02, -1.1783e-02,  ...,  1.1837e-02,\n",
      "         -1.1754e-02, -1.1909e-02],\n",
      "        [ 1.1850e-02, -1.1785e-03, -1.1794e-02,  ...,  1.1761e-02,\n",
      "         -1.1795e-02, -1.1485e-02]], requires_grad=True), Parameter containing:\n",
      "tensor([[-5.0791e-03,  2.2808e-02,  2.4775e-04,  ..., -1.2551e-02,\n",
      "         -1.3099e-02,  3.6910e-02],\n",
      "        [ 1.4271e-02, -7.3198e-03, -1.7716e-02,  ..., -1.8277e-02,\n",
      "          1.6017e-02, -1.8744e-02],\n",
      "        [-1.4961e-03, -9.6891e-03,  3.1767e-02,  ..., -1.1961e-03,\n",
      "         -1.3546e-02,  3.7508e-02],\n",
      "        ...,\n",
      "        [-9.3780e-03,  5.9206e-03,  1.2783e-02,  ..., -2.7266e-02,\n",
      "          1.0808e-02,  1.5535e-03],\n",
      "        [-3.6973e-02, -2.5496e-02, -1.0252e-02,  ..., -2.6443e-05,\n",
      "         -3.4569e-03, -2.3277e-02],\n",
      "        [ 1.9170e-02, -3.9319e-05,  3.1612e-02,  ...,  2.7344e-02,\n",
      "         -3.9192e-03,  2.9640e-02]], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0057,  0.0112, -0.0108,  ...,  0.0112,  0.0109, -0.0108],\n",
      "        [-0.0048,  0.0114, -0.0044,  ...,  0.0063,  0.0107, -0.0113],\n",
      "        [-0.0116,  0.0114, -0.0111,  ...,  0.0117,  0.0112, -0.0111],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0115,  0.0113,  ..., -0.0041, -0.0107,  0.0112],\n",
      "        [-0.0107,  0.0115, -0.0058,  ...,  0.0117,  0.0064, -0.0114],\n",
      "        [ 0.0114, -0.0114,  0.0110,  ..., -0.0114, -0.0110,  0.0104]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0637,  0.0089, -0.0066,  ...,  0.0374,  0.0169, -0.0409],\n",
      "        [ 0.0579,  0.0433,  0.0067,  ..., -0.0330, -0.0191,  0.0418],\n",
      "        [-0.0265, -0.0064,  0.0260,  ..., -0.0585,  0.0102, -0.0167],\n",
      "        ...,\n",
      "        [-0.0598,  0.0422,  0.0195,  ..., -0.0591, -0.0251,  0.0174],\n",
      "        [-0.0371,  0.0328, -0.0284,  ...,  0.0155, -0.0120,  0.0420],\n",
      "        [-0.0348,  0.0319,  0.0140,  ...,  0.0273,  0.0448,  0.0410]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0120, -0.0119,  0.0120,  ...,  0.0120,  0.0118,  0.0120],\n",
      "        [ 0.0119,  0.0120, -0.0058,  ..., -0.0119, -0.0120, -0.0115],\n",
      "        [-0.0119, -0.0118, -0.0113,  ...,  0.0118,  0.0116,  0.0119],\n",
      "        ...,\n",
      "        [ 0.0116,  0.0117, -0.0118,  ..., -0.0120, -0.0116, -0.0116],\n",
      "        [-0.0120, -0.0120,  0.0120,  ...,  0.0116,  0.0120,  0.0120],\n",
      "        [ 0.0118,  0.0118, -0.0113,  ..., -0.0119, -0.0118, -0.0119]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0316, -0.0360, -0.0053,  ...,  0.0046, -0.0082,  0.0079],\n",
      "        [-0.0344, -0.0266,  0.0067,  ..., -0.0017, -0.0010,  0.0143],\n",
      "        [ 0.0045,  0.0149,  0.0152,  ...,  0.0248,  0.0142,  0.0200],\n",
      "        ...,\n",
      "        [-0.0314,  0.0029,  0.0158,  ..., -0.0238, -0.0108, -0.0202],\n",
      "        [-0.0145, -0.0064,  0.0327,  ..., -0.0037,  0.0156, -0.0120],\n",
      "        [-0.0270,  0.0366,  0.0033,  ...,  0.0105,  0.0226,  0.0087]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0116,  0.0111, -0.0113,  ...,  0.0115, -0.0114, -0.0111],\n",
      "        [ 0.0119,  0.0119, -0.0118,  ...,  0.0119, -0.0116, -0.0106],\n",
      "        [ 0.0110,  0.0110, -0.0113,  ...,  0.0107, -0.0112, -0.0110],\n",
      "        ...,\n",
      "        [-0.0118, -0.0115,  0.0112,  ..., -0.0118,  0.0116,  0.0117],\n",
      "        [ 0.0031,  0.0112, -0.0113,  ...,  0.0113, -0.0060, -0.0052],\n",
      "        [-0.0114, -0.0107,  0.0113,  ..., -0.0111,  0.0113,  0.0111]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0320,  0.0522, -0.0533,  ...,  0.0122,  0.0159,  0.0204],\n",
      "        [ 0.0131,  0.0234,  0.0042,  ...,  0.0253,  0.0615,  0.0035],\n",
      "        [-0.0214,  0.0172,  0.0433,  ...,  0.0046, -0.0484,  0.0236],\n",
      "        ...,\n",
      "        [-0.0174,  0.0241, -0.0154,  ..., -0.0278,  0.0312,  0.0421],\n",
      "        [-0.0405, -0.0647,  0.0573,  ...,  0.0255,  0.0411, -0.0178],\n",
      "        [ 0.0283, -0.0336,  0.0122,  ..., -0.0156, -0.0107, -0.0388]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0119,  0.0115,  0.0009,  ...,  0.0119, -0.0116,  0.0119],\n",
      "        [ 0.0003, -0.0051, -0.0119,  ...,  0.0117, -0.0114,  0.0114],\n",
      "        [-0.0119,  0.0116, -0.0120,  ..., -0.0044,  0.0115, -0.0119],\n",
      "        ...,\n",
      "        [ 0.0116, -0.0118,  0.0119,  ...,  0.0119, -0.0114,  0.0118],\n",
      "        [-0.0116, -0.0119, -0.0117,  ..., -0.0111, -0.0115, -0.0115],\n",
      "        [ 0.0115, -0.0112,  0.0119,  ...,  0.0015, -0.0047,  0.0111]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0083, -0.0067,  0.0137,  ...,  0.0076,  0.0179, -0.0055],\n",
      "        [-0.0175,  0.0104, -0.0323,  ...,  0.0165, -0.0315, -0.0038],\n",
      "        [ 0.0023, -0.0278,  0.0100,  ...,  0.0264,  0.0174, -0.0231],\n",
      "        ...,\n",
      "        [ 0.0091, -0.0138,  0.0228,  ..., -0.0145,  0.0018, -0.0005],\n",
      "        [ 0.0302,  0.0023,  0.0076,  ...,  0.0132,  0.0118,  0.0017],\n",
      "        [ 0.0377,  0.0077,  0.0009,  ..., -0.0058,  0.0244, -0.0001]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0064,  0.0107,  0.0115,  ..., -0.0113, -0.0107, -0.0118],\n",
      "        [-0.0115,  0.0117,  0.0118,  ..., -0.0018, -0.0113, -0.0117],\n",
      "        [-0.0110,  0.0114,  0.0110,  ..., -0.0116, -0.0111, -0.0117],\n",
      "        ...,\n",
      "        [ 0.0110, -0.0116, -0.0114,  ...,  0.0048,  0.0109,  0.0118],\n",
      "        [-0.0023, -0.0050,  0.0115,  ..., -0.0111,  0.0053, -0.0118],\n",
      "        [ 0.0110, -0.0114, -0.0113,  ...,  0.0114,  0.0113,  0.0118]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0586,  0.0603,  0.0155,  ..., -0.0112, -0.0346,  0.0113],\n",
      "        [-0.0263,  0.0386, -0.0270,  ...,  0.0040, -0.0438,  0.0551],\n",
      "        [-0.0365, -0.0251, -0.0196,  ..., -0.0046,  0.0200, -0.0467],\n",
      "        ...,\n",
      "        [-0.0128,  0.0496, -0.0449,  ..., -0.0375, -0.0316, -0.0157],\n",
      "        [-0.0300, -0.0380,  0.0282,  ..., -0.0151,  0.0625, -0.0376],\n",
      "        [-0.0449, -0.0346,  0.0096,  ...,  0.0044,  0.0272, -0.0349]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0079, -0.0112, -0.0118,  ...,  0.0114, -0.0114, -0.0020],\n",
      "        [-0.0118,  0.0119, -0.0117,  ..., -0.0119,  0.0119,  0.0119],\n",
      "        [ 0.0104, -0.0111, -0.0119,  ...,  0.0092, -0.0099, -0.0088],\n",
      "        ...,\n",
      "        [-0.0109,  0.0119, -0.0118,  ...,  0.0075, -0.0091,  0.0119],\n",
      "        [ 0.0118, -0.0119,  0.0117,  ...,  0.0113, -0.0117, -0.0119],\n",
      "        [-0.0118, -0.0113, -0.0118,  ...,  0.0083,  0.0042,  0.0047]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0005,  0.0093, -0.0122,  ..., -0.0351,  0.0133,  0.0197],\n",
      "        [-0.0123,  0.0285,  0.0323,  ...,  0.0303, -0.0104, -0.0239],\n",
      "        [-0.0314, -0.0335, -0.0132,  ...,  0.0178,  0.0043, -0.0240],\n",
      "        ...,\n",
      "        [-0.0033,  0.0042, -0.0351,  ...,  0.0043, -0.0105,  0.0242],\n",
      "        [ 0.0049,  0.0034,  0.0085,  ...,  0.0110, -0.0082,  0.0336],\n",
      "        [-0.0114, -0.0161,  0.0270,  ..., -0.0178,  0.0234,  0.0070]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0109,  0.0007,  0.0106,  ...,  0.0014, -0.0044, -0.0109],\n",
      "        [-0.0083,  0.0116,  0.0114,  ...,  0.0085, -0.0119,  0.0083],\n",
      "        [ 0.0116, -0.0117,  0.0112,  ...,  0.0116, -0.0109, -0.0108],\n",
      "        ...,\n",
      "        [-0.0116,  0.0117, -0.0111,  ..., -0.0115,  0.0056,  0.0108],\n",
      "        [-0.0114,  0.0118, -0.0056,  ..., -0.0043, -0.0108,  0.0109],\n",
      "        [-0.0117,  0.0117, -0.0110,  ..., -0.0115, -0.0117,  0.0063]],\n",
      "       requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "#weight_names = ['layers.0.fc1.lora_A', 'layers.0.fc1.lora_B', 'layers.0.fc2.lora_A', 'layers.0.fc2.lora_B', 'layers.1.fc1.lora_A', 'layers.1.fc1.lora_B', 'layers.1.fc2.lora_A', 'layers.1.fc2.lora_B', 'layers.2.fc1.lora_A', 'layers.2.fc1.lora_B', 'layers.2.fc2.lora_A', 'layers.2.fc2.lora_B', 'layers.3.fc1.lora_A', 'layers.3.fc1.lora_B', 'layers.3.fc2.lora_A', 'layers.3.fc2.lora_B', 'layers.4.fc1.lora_A', 'layers.4.fc1.lora_B', 'layers.4.fc2.lora_A', 'layers.4.fc2.lora_B', 'layers.5.fc1.lora_A', 'layers.5.fc1.lora_B', 'layers.5.fc2.lora_A', 'layers.5.fc2.lora_B']\n",
    "weight_names = ['model.layers[0].fc1.lora_A', 'model.layers[0].fc1.lora_B', 'model.layers[0].fc2.lora_A', 'model.layers[0].fc2.lora_B', 'model.layers[1].fc1.lora_A', 'model.layers[1].fc1.lora_B', 'model.layers[1].fc2.lora_A', 'model.layers[1].fc2.lora_B', 'model.layers[2].fc1.lora_A', 'model.layers[2].fc1.lora_B', 'model.layers[2].fc2.lora_A', 'model.layers[2].fc2.lora_B', 'model.layers[3].fc1.lora_A', 'model.layers[3].fc1.lora_B', 'model.layers[3].fc2.lora_A', 'model.layers[3].fc2.lora_B', 'model.layers[4].fc1.lora_A', 'model.layers[4].fc1.lora_B', 'model.layers[4].fc2.lora_A', 'model.layers[4].fc2.lora_B', 'model.layers[5].fc1.lora_A', 'model.layers[5].fc1.lora_B', 'model.layers[5].fc2.lora_A', 'model.layers[5].fc2.lora_B']\n",
    "\n",
    "\n",
    "\n",
    "#for item in weight_names:\n",
    "#    lora.nn.init.normal_(eval(item), std=0.02)\n",
    "\n",
    "\n",
    "lora_before_training = [model.layers[0].fc1.lora_A, model.layers[0].fc1.lora_B, model.layers[0].fc2.lora_A, model.layers[0].fc2.lora_B, \n",
    "                        model.layers[1].fc1.lora_A, model.layers[1].fc1.lora_B, model.layers[1].fc2.lora_A, model.layers[1].fc2.lora_B, \n",
    "                        model.layers[2].fc1.lora_A, model.layers[2].fc1.lora_B, model.layers[2].fc2.lora_A, model.layers[2].fc2.lora_B,\n",
    "                        model.layers[3].fc1.lora_A, model.layers[3].fc1.lora_B, model.layers[3].fc2.lora_A, model.layers[3].fc2.lora_B,\n",
    "                        model.layers[4].fc1.lora_A, model.layers[4].fc1.lora_B, model.layers[4].fc2.lora_A, model.layers[4].fc2.lora_B,\n",
    "                        model.layers[5].fc1.lora_A, model.layers[5].fc1.lora_B, model.layers[5].fc2.lora_A, model.layers[5].fc2.lora_B]\n",
    "\n",
    "print(lora_before_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12037"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "\n",
    "# Read fasta file to csv with SeqIO\n",
    "fasta_file = 'data/uniprotkb_reviewed_true_AND_annotation_2023_07_12.fasta'\n",
    "\n",
    "with open(fasta_file) as fasta_file:  # Will close handle cleanly\n",
    "    id = []\n",
    "    sequence = []\n",
    "    for seq_record in SeqIO.parse(fasta_file, 'fasta'):  # (generator)\n",
    "        id.append(seq_record.id)\n",
    "        sequence.append(str(seq_record.seq))\n",
    "\n",
    "tuples = list(zip(id, sequence))\n",
    "\n",
    "# Remove length > 1022\n",
    "tuples = [t for t in tuples if len(t[1]) <= 1022]\n",
    "\n",
    "# create dataframe\n",
    "# df = pd.DataFrame(tuples, columns=['id', 'sequence'])\n",
    "# df = df[df['sequence'].str.len() <= 1022]\n",
    "\n",
    "data = tuples\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "len(batch_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# forward + backward + optimize\n",
    "input = batch_tokens[0:1000]\n",
    "y = input.clone()\n",
    "mask_index_list = []\n",
    "\n",
    "# Mask 15% of the sequence\n",
    "for i in range(len(y)):\n",
    "    # Remove all padding, cls, eos tokens\n",
    "    mask_arr = (y[i] != model.padding_idx) * (y[i] != model.cls_idx) * (y[i] != model.eos_idx)\n",
    "    short_seq = y[i][mask_arr]\n",
    "    masking_index = random.sample(range(len(short_seq)), int(0.15*len(short_seq)))\n",
    "    # Add one value for each index to account for skipped BOS token in original sequence\n",
    "    masking_index = [i + 1 for i in masking_index]\n",
    "    # Randomly input old character, mask, or random character\n",
    "    mask = np.random.choice(['mask', 'old', 'random'], len(masking_index), p=[0.8, 0.1, 0.1])\n",
    "\n",
    "    # Lists masking_index and mask to dictionary\n",
    "    mask_and_index = dict(zip(masking_index, mask))\n",
    "    \n",
    "    # Loop through dictionary and replace values in y\n",
    "    for masking_index, mask in mask_and_index.items():\n",
    "        if mask == 'old':\n",
    "            continue\n",
    "        if mask == 'random':\n",
    "            # generate random token\n",
    "            y[i][masking_index] = np.random.choice(range(4,29))\n",
    "        if mask == 'mask':\n",
    "            y[i][masking_index] = model.mask_idx\n",
    "\n",
    "    mask_index_list.append(list(mask_and_index.keys()))\n",
    "\n",
    "# Pad and set mask_index_list to tensor\n",
    "mask_index = []\n",
    "for i in range(len(mask_index_list)):\n",
    "    mask_index.append(torch.tensor(mask_index_list[i]))\n",
    "mask_index = torch.nn.utils.rnn.pad_sequence(mask_index, batch_first=True, padding_value=0)\n",
    "\n",
    "# Set x to be one-hot encoded amino acid at each position\n",
    "target = torch.zeros(len(input), len(input[0]), len(alphabet.all_toks))\n",
    "\n",
    "for i in range(len(input)):\n",
    "    for j in range(len(input[i])):\n",
    "        # print(\"i: \" + str(i) + \" j: \" + str(j) + \" input[i][j]: \" + str(int(input[i][j])))\n",
    "        target[i][j][int(input[i][j])] = 1\n",
    "\n",
    "# Edit print option for testing\n",
    "#torch.set_printoptions(profile=\"full\")\n",
    "torch.set_printoptions(profile=\"default\")\n",
    "\n",
    "print(len(target))\n",
    "print(len(y))\n",
    "print(len(mask_index))\n",
    "\n",
    "data_dict = {'target': target, 'data': y, 'mask_index': mask_index}\n",
    "\n",
    "data_inputs = []\n",
    "#Generate a list of dictionaries for each sequence\n",
    "for i in range(len(data_dict['target'])):\n",
    "    data_inputs.append({'target': data_dict['target'][i], 'data': data_dict['data'][i], 'mask_index': data_dict['mask_index'][i]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING! ###\n",
    "\n",
    "# Set up model for Training LoRA Weights\n",
    "lora.mark_only_lora_as_trainable(model)\n",
    "\n",
    "# Select device and move model to device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Set criterion and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Setup Dataloader\n",
    "dataset = data_inputs\n",
    "train, val = random_split(dataset, [math.ceil(0.9*len(dataset)), math.floor(0.1*len(dataset))])\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=32)\n",
    "val_loader = DataLoader(val, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on epoch number:  1\n",
      "Working on batch number:  1\n",
      "[1, 1] batch loss: 785.916 running loss: 785.916\n",
      "Working on batch number:  2\n",
      "[1, 2] batch loss: 779.286 running loss: 1565.203\n",
      "Working on batch number:  3\n",
      "[1, 3] batch loss: 739.778 running loss: 2304.981\n",
      "Working on batch number:  4\n",
      "[1, 4] batch loss: 741.516 running loss: 3046.497\n",
      "Working on batch number:  5\n",
      "[1, 5] batch loss: 735.762 running loss: 3782.259\n",
      "Working on batch number:  6\n",
      "[1, 6] batch loss: 757.762 running loss: 4540.021\n",
      "Working on batch number:  7\n",
      "[1, 7] batch loss: 718.927 running loss: 5258.949\n",
      "Working on batch number:  8\n",
      "[1, 8] batch loss: 707.476 running loss: 5966.425\n",
      "Working on batch number:  9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/stor/work/Wilke/afeller/esm_embeddings/ESM_LoRA_V2.ipynb Cell 9\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwilkcomp02/stor/work/Wilke/afeller/esm_embeddings/ESM_LoRA_V2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m mask_index \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mmask_index\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwilkcomp02/stor/work/Wilke/afeller/esm_embeddings/ESM_LoRA_V2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Generate outputs\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bwilkcomp02/stor/work/Wilke/afeller/esm_embeddings/ESM_LoRA_V2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m y \u001b[39m=\u001b[39m model(y)[\u001b[39m'\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwilkcomp02/stor/work/Wilke/afeller/esm_embeddings/ESM_LoRA_V2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Pad location of unmasked residues in y and y_hat\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwilkcomp02/stor/work/Wilke/afeller/esm_embeddings/ESM_LoRA_V2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(mask_index)):\n",
      "File \u001b[0;32m~/miniconda3/envs/esm/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/stor/work/Wilke/afeller/esm_embeddings/esmLoRA/esm/model/esm2.py:115\u001b[0m, in \u001b[0;36mESM2.forward\u001b[0;34m(self, tokens, repr_layers, need_head_weights, return_contacts)\u001b[0m\n\u001b[1;32m    112\u001b[0m     padding_mask \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mfor\u001b[39;00m layer_idx, layer \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers):\n\u001b[0;32m--> 115\u001b[0m     x, attn \u001b[39m=\u001b[39m layer(\n\u001b[1;32m    116\u001b[0m         x,\n\u001b[1;32m    117\u001b[0m         self_attn_padding_mask\u001b[39m=\u001b[39;49mpadding_mask,\n\u001b[1;32m    118\u001b[0m         need_head_weights\u001b[39m=\u001b[39;49mneed_head_weights,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    120\u001b[0m     \u001b[39mif\u001b[39;00m (layer_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39min\u001b[39;00m repr_layers:\n\u001b[1;32m    121\u001b[0m         hidden_representations[layer_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/esm/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/stor/work/Wilke/afeller/esm_embeddings/esmLoRA/esm/modules.py:126\u001b[0m, in \u001b[0;36mTransformerLayer.forward\u001b[0;34m(self, x, self_attn_mask, self_attn_padding_mask, need_head_weights)\u001b[0m\n\u001b[1;32m    124\u001b[0m residual \u001b[39m=\u001b[39m x\n\u001b[1;32m    125\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn_layer_norm(x)\n\u001b[0;32m--> 126\u001b[0m x, attn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[1;32m    127\u001b[0m     query\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    128\u001b[0m     key\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    129\u001b[0m     value\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    130\u001b[0m     key_padding_mask\u001b[39m=\u001b[39;49mself_attn_padding_mask,\n\u001b[1;32m    131\u001b[0m     need_weights\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    132\u001b[0m     need_head_weights\u001b[39m=\u001b[39;49mneed_head_weights,\n\u001b[1;32m    133\u001b[0m     attn_mask\u001b[39m=\u001b[39;49mself_attn_mask,\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    135\u001b[0m x \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m x\n\u001b[1;32m    137\u001b[0m residual \u001b[39m=\u001b[39m x\n",
      "File \u001b[0;32m~/miniconda3/envs/esm/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/stor/work/Wilke/afeller/esm_embeddings/esmLoRA/esm/multihead_attention.py:374\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, incremental_state, need_weights, static_kv, attn_mask, before_softmax, need_head_weights)\u001b[0m\n\u001b[1;32m    370\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights\u001b[39m.\u001b[39mview(bsz, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, tgt_len, src_len)\n\u001b[1;32m    371\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights\u001b[39m.\u001b[39mmasked_fill(\n\u001b[1;32m    372\u001b[0m         key_padding_mask\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mbool), \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-inf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    373\u001b[0m     )\n\u001b[0;32m--> 374\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights\u001b[39m.\u001b[39;49mview(bsz \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, tgt_len, src_len)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m before_softmax:\n\u001b[1;32m    377\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_weights, v\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(2):\n",
    "    batch_number = 0\n",
    "    running_loss = 0.0\n",
    "    print(\"Working on epoch number: \", epoch+1)\n",
    "    for batch in train_loader:\n",
    "        batch_number+=1\n",
    "        print(\"Working on batch number: \", batch_number)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        y_hat = batch['target']\n",
    "        y = batch['data']\n",
    "        mask_index = batch['mask_index']\n",
    "        \n",
    "        # Generate outputs\n",
    "        y = model(y)['logits']\n",
    "        \n",
    "        # Pad location of unmasked residues in y and y_hat\n",
    "        for i in range(len(mask_index)):\n",
    "            y_hat[i][mask_index[i][mask_index[i] != 0]] = 1\n",
    "            y[i][mask_index[i][mask_index[i] != 0]] = 1\n",
    "\n",
    "        # Calculate loss and backpropagate\n",
    "        # for i in mask_index:\n",
    "        #     print(i)\n",
    "        # print(torch.nn.CrossEntropyLoss(reduction='none')(y, y_hat))\n",
    "\n",
    "        loss = criterion(y, y_hat)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        print(f'[{epoch + 1}, {batch_number}] batch loss: {loss.item():.3f} running loss: {running_loss:.3f}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41,\n",
       " 13,\n",
       " 103,\n",
       " 122,\n",
       " 108,\n",
       " 7,\n",
       " 155,\n",
       " 44,\n",
       " 158,\n",
       " 77,\n",
       " 30,\n",
       " 93,\n",
       " 82,\n",
       " 99,\n",
       " 102,\n",
       " 124,\n",
       " 146,\n",
       " 62,\n",
       " 85,\n",
       " 3,\n",
       " 97,\n",
       " 164,\n",
       " 141,\n",
       " 78,\n",
       " 142,\n",
       " 119]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[0][mask_index[0][mask_index[0] != 0]])\n",
    "\n",
    "y[0][mask_index[0][mask_index[0] != 0]]\n",
    "y_hat[0][mask_index[0][mask_index[0] != 0]]\n",
    "\n",
    "#mask_index\n",
    "thing = mask_index[0][mask_index[0] != 0]\n",
    "thing.tolist()\n",
    "#len(mask_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0089,  0.0239, -0.0300,  ...,  0.0442,  0.0503,  0.0449],\n",
       "         [ 0.0088, -0.0534,  0.0089,  ...,  0.0220,  0.0446, -0.0437],\n",
       "         [-0.0215,  0.0343,  0.0420,  ..., -0.0398,  0.0237, -0.0056],\n",
       "         ...,\n",
       "         [-0.0499, -0.0167, -0.0011,  ..., -0.0099,  0.0430, -0.0011],\n",
       "         [-0.0497, -0.0211, -0.0406,  ..., -0.0469, -0.0152, -0.0057],\n",
       "         [-0.0548,  0.0412, -0.0019,  ..., -0.0253, -0.0369, -0.0421]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0019, -0.0019,  0.0019,  ...,  0.0019, -0.0019,  0.0018],\n",
       "         [-0.0020,  0.0020, -0.0020,  ..., -0.0019,  0.0020, -0.0020],\n",
       "         [-0.0019, -0.0019, -0.0020,  ...,  0.0020, -0.0019, -0.0020],\n",
       "         ...,\n",
       "         [-0.0020, -0.0019, -0.0019,  ...,  0.0020,  0.0015, -0.0020],\n",
       "         [ 0.0020,  0.0020,  0.0020,  ..., -0.0020,  0.0020,  0.0019],\n",
       "         [-0.0020,  0.0020, -0.0020,  ...,  0.0017,  0.0020, -0.0020]],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_after_training = [model.layers[0].fc1.lora_A, model.layers[0].fc1.lora_B, model.layers[0].fc2.lora_A, model.layers[0].fc2.lora_B, \n",
    "                        model.layers[1].fc1.lora_A, model.layers[1].fc1.lora_B, model.layers[1].fc2.lora_A, model.layers[1].fc2.lora_B, \n",
    "                        model.layers[2].fc1.lora_A, model.layers[2].fc1.lora_B, model.layers[2].fc2.lora_A, model.layers[2].fc2.lora_B,\n",
    "                        model.layers[3].fc1.lora_A, model.layers[3].fc1.lora_B, model.layers[3].fc2.lora_A, model.layers[3].fc2.lora_B,\n",
    "                        model.layers[4].fc1.lora_A, model.layers[4].fc1.lora_B, model.layers[4].fc2.lora_A, model.layers[4].fc2.lora_B,\n",
    "                        model.layers[5].fc1.lora_A, model.layers[5].fc1.lora_B, model.layers[5].fc2.lora_A, model.layers[5].fc2.lora_B]\n",
    "\n",
    "print(lora_after_training)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
